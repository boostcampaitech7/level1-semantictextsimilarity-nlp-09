{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ë„¤ì´ë²„ ë§ì¶¤ë²• api ì‚¬ìš©\n",
    "- ì´ëª¨í‹°ì½˜ ì‚¬ë¼ì§: 'ğŸ‘ŒğŸ‘ŒğŸ‘Œ' -> ''\n",
    "- ì‹ ì¡°ì–´ ë“±ì€ ì•ˆë°”ë€œ: 'ê°¬ì„±' -> 'ê°¬ì„±', 'íˆì´ì•¼' -> 'íˆì´ì•¼' ë“±\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import html\n",
    "from pykospacing import Spacing\n",
    "from tqdm import tqdm\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "\n",
    "def prep_spacing(text):\n",
    "    spacing = Spacing()\n",
    "    return spacing(text)\n",
    "\n",
    "\n",
    "def prep_naver(text):\n",
    "    def get_passport_key():\n",
    "        url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EB%A7%9E%EC%B6%A4%EB%B2%95%EA%B2%80%EC%82%AC%EA%B8%B0\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            match = re.search(r'passportKey=([a-zA-Z0-9-_]+)', html)\n",
    "            if match:\n",
    "                passport_key = match.group(1)\n",
    "                return passport_key\n",
    "            else:\n",
    "                raise ValueError(\"passportKey not found in the HTML response.\")\n",
    "        else:\n",
    "            raise ConnectionError(f\"Failed to fetch the page, status code: {response.status_code}\")\n",
    "\n",
    "    # ë§ì¶¤ë²• ê²€ì‚¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜\n",
    "    def _spell_check_request(text, passport_key):\n",
    "        payload = {\n",
    "            'passportKey': passport_key,\n",
    "            '_callback': passport_key,\n",
    "            'q': text,\n",
    "            'color_blindness': '0'\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'referer': 'https://search.naver.com/',\n",
    "        }\n",
    "\n",
    "        start_time = time.time()\n",
    "        r = requests.get(\"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy\", params=payload, headers=headers)\n",
    "        passed_time = time.time() - start_time\n",
    "\n",
    "        json_match = re.search(r'\\{.*\\}', r.text)\n",
    "        if json_match:\n",
    "            json_data = json_match.group(0)\n",
    "            data = json.loads(json_data)\n",
    "            html = data['message']['result']['html']\n",
    "            return _remove_tags(html)\n",
    "        else:\n",
    "            raise ValueError(\"No JSON data found in the response.\")\n",
    "\n",
    "    def _remove_tags(text):\n",
    "        text = '<content>{}</content>'.format(text).replace('<br>','')\n",
    "        result = ''.join(re.sub(r'<[^>]+>', '', text))\n",
    "        return result\n",
    "\n",
    "    def check(text, passport_key):\n",
    "        try:\n",
    "            return _spell_check_request(text, passport_key)\n",
    "        except ValueError as e:\n",
    "            if 'No JSON data found in the response' in str(e):\n",
    "                print(\"passport_key expired, fetching a new one.\")\n",
    "                passport_key = get_passport_key()  # ìƒˆë¡œìš´ passport_key ê°€ì ¸ì˜¤ê¸°\n",
    "                return _spell_check_request(text, passport_key)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    passport_key = get_passport_key()\n",
    "    text = html.unescape(check(text, passport_key))\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def prep_repeats(text):\n",
    "    \n",
    "    # ë°˜ë³µë˜ëŠ” ê°íƒ„ì‚¬ë‚˜ ë¹„ìŠ·í•œ í‘œí˜„ì„ ì¤„ì´ëŠ” í•¨ìˆ˜\n",
    "    def normalize_text(text):\n",
    "        # ë°˜ë³µë˜ëŠ” ê¸€ì(ê°íƒ„ì‚¬, ì›ƒìŒì†Œë¦¬ ë“±)ë¥¼ ìµœëŒ€ 2ê°œë¡œ ì¤„ì„\n",
    "        normalized_text = repeat_normalize(text, num_repeats=2)\n",
    "        return normalized_text\n",
    "    \n",
    "    text = normalize_text(text)\n",
    "\n",
    "    # ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ, ì (.) ë“±ì˜ ë¬¸ì¥ ë¶€í˜¸ ë°˜ë³µì„ ìµœëŒ€ 2ê°œë¡œ ì¤„ì„\n",
    "    text = re.sub(r'([!?.])\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # í•œê¸€ ììŒ, ëª¨ìŒ ë°˜ë³µ (ì˜ˆ: ã…‹ã…‹ã…‹, ã… ã… ã… ã…  ë“±)\n",
    "    text = re.sub(r'([ã„±-ã…ã…-ã…£])\\1{2,}', r'\\1\\1', text)\n",
    "            \n",
    "    # ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ ë¬¸ìì˜ ë°˜ë³µ ì¤„ì´ê¸°\n",
    "    text = re.sub(r'([\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F])\\1{2,}', r'\\1\\1', text)  # ì´ëª¨ì§€\n",
    "    text = re.sub(r'([#$%&*])\\1{2,}', r'\\1\\1', text)  # íŠ¹ìˆ˜ë¬¸ì\n",
    "\n",
    "    # í‘œì¤€ ê³µë°± ì™¸ ë‹¤ë¥¸ ê³µë°± ë¬¸ìë“¤ë„ ì²˜ë¦¬\n",
    "    text = re.sub(r'[\\u00A0\\u1680\\u2000-\\u200A\\u202F\\u205F\\u3000]', ' ', text)\n",
    "        \n",
    "    # ì—¬ëŸ¬ ê°œì˜ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì¤„ì„\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess(df):\n",
    "    df['sentence_1'] = df['sentence_1'].apply(prep_repeats)\n",
    "    df['sentence_2'] = df['sentence_2'].apply(prep_repeats)\n",
    "    # df['sentence_1'] = df['sentence_1'].apply(prep_naver)\n",
    "    # df['sentence_2'] = df['sentence_2'].apply(prep_naver)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ë„¤ì´ë²„ ë§ì¶¤ë²• api ì‚¬ìš©\n",
    "- ì´ëª¨í‹°ì½˜ ì‚¬ë¼ì§: 'ğŸ‘ŒğŸ‘ŒğŸ‘Œ' -> ''\n",
    "- ì‹ ì¡°ì–´ ë“±ì€ ì•ˆë°”ë€œ: 'ê°¬ì„±' -> 'ê°¬ì„±', 'íˆì´ì•¼' -> 'íˆì´ì•¼' ë“±\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "\n",
    "def check_spell(dataframe):\n",
    "    def get_passport_key():\n",
    "        url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EB%A7%9E%EC%B6%A4%EB%B2%95%EA%B2%80%EC%82%AC%EA%B8%B0\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            match = re.search(r'passportKey=([a-zA-Z0-9-_]+)', html)\n",
    "            if match:\n",
    "                passport_key = match.group(1)\n",
    "                print(f\"passportKey found: {passport_key}\")\n",
    "                return passport_key\n",
    "            else:\n",
    "                raise ValueError(\"passportKey not found in the HTML response.\")\n",
    "        else:\n",
    "            raise ConnectionError(f\"Failed to fetch the page, status code: {response.status_code}\")\n",
    "\n",
    "    # ë§ì¶¤ë²• ê²€ì‚¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜\n",
    "    def _spell_check_request(text, passport_key):\n",
    "        payload = {\n",
    "            'passportKey': passport_key,\n",
    "            '_callback': passport_key,\n",
    "            'q': text,\n",
    "            'color_blindness': '0'\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'referer': 'https://search.naver.com/',\n",
    "        }\n",
    "\n",
    "        start_time = time.time()\n",
    "        r = requests.get(\"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy\", params=payload, headers=headers)\n",
    "        passed_time = time.time() - start_time\n",
    "\n",
    "        json_match = re.search(r'\\{.*\\}', r.text)\n",
    "        if json_match:\n",
    "            json_data = json_match.group(0)\n",
    "            data = json.loads(json_data)\n",
    "            html = data['message']['result']['html']\n",
    "            return _remove_tags(html)\n",
    "        else:\n",
    "            raise ValueError(\"No JSON data found in the response.\")\n",
    "\n",
    "    def _remove_tags(text):\n",
    "        text = '<content>{}</content>'.format(text).replace('<br>','')\n",
    "        result = ''.join(re.sub(r'<[^>]+>', '', text))\n",
    "        return result\n",
    "\n",
    "    def check(text, passport_key):\n",
    "        try:\n",
    "            return _spell_check_request(text, passport_key)\n",
    "        except ValueError as e:\n",
    "            if 'No JSON data found in the response' in str(e):\n",
    "                print(\"passport_key expired, fetching a new one.\")\n",
    "                passport_key = get_passport_key()  # ìƒˆë¡œìš´ passport_key ê°€ì ¸ì˜¤ê¸°\n",
    "                return _spell_check_request(text, passport_key)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    passport_key = get_passport_key()\n",
    "\n",
    "    for i in tqdm(range(len(dataframe['sentence_1'])), desc='check_spell'):\n",
    "        dataframe.loc[i, 'sentence_1'] = html.unescape(check(dataframe.loc[i, 'sentence_1'], passport_key))\n",
    "        dataframe.loc[i, 'sentence_2'] = html.unescape(check(dataframe.loc[i, 'sentence_2'], passport_key))        \n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passportKey found: 2caa5e5496fed85692709081d304c63cf6eaa3bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "check_spell: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9324/9324 [10:52<00:00, 14.28it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train_preprop_v2 = preprocess(train)\n",
    "train_preprop_v2 = check_spell(train_preprop_v2)\n",
    "train_preprop_v2.to_csv('train_preprop_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passportKey found: 2caa5e5496fed85692709081d304c63cf6eaa3bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "check_spell: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 550/550 [00:36<00:00, 15.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dev = pd.read_csv('dev.csv')\n",
    "dev_preprop_v2 = preprocess(dev)\n",
    "dev_preprop_v2 = check_spell(dev_preprop_v2)\n",
    "dev_preprop_v2.to_csv('dev_preprop_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_preprop_v2 = pd.read_csv('dev_preprop_v2.csv')\n",
    "dev_preprop_v2_no_label = dev_preprop_v2.drop(columns=['label', 'binary-label'])\n",
    "dev_preprop_v2_no_label.to_csv('dev_preprop_v2_no_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passportKey found: 2caa5e5496fed85692709081d304c63cf6eaa3bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "check_spell: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1100/1100 [01:22<00:00, 13.35it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test_preprop_v2 = preprocess(test)\n",
    "test_preprop_v2 = check_spell(test_preprop_v2)\n",
    "test_preprop_v2.to_csv('test_preprop_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1340446/1849768944.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentence_1'] = df['sentence_1'].apply(prep_repeats)\n",
      "/tmp/ipykernel_1340446/1849768944.py:120: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentence_2'] = df['sentence_2'].apply(prep_repeats)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>boostcamp-sts-v1-train-020</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>ì•ë¨¸ë¦¬ ìƒˆë¡œ í•˜ì…¨ìŠµë‹ˆë‹¤. ^^</td>\n",
       "      <td>ê°€ë°©ì— ë„£ì–´ ë‹¤ë‹ˆë©´ì„œ ì¡°ê¸ˆì”© ë¨¹ìŠµë‹ˆë‹¤. ^^</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>boostcamp-sts-v1-train-021</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>ê¹€ê¸°ë• ì¡°ì¬í˜„ ì„±í­í–‰ ì² ì €íˆ ìˆ˜ì‚¬í•´ ì£¼ì„¸ìš”!</td>\n",
       "      <td>ê¹€ê¸°ë•Â·ì¡°ì¬í˜„ ì„±í­í–‰ ì˜í˜¹ ì² ì €íˆ ìˆ˜ì‚¬í•˜ë¼!</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>boostcamp-sts-v1-train-022</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>ë‹µë‹µí•  ë•Œ ë³´ë©´ ì†ì´ ë»¥ ëš«ë¦´ ê²ƒ ê°™ì•„ìš”</td>\n",
       "      <td>ì–‘ë³´ë‹¨ í•œì… ë¨¹ëŠ” ìˆœê°„ ê³ ì‚ í’€ë¦´ ê²ƒ ê°™ì•„ìš” ã…‹ã…‹</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>boostcamp-sts-v1-train-023</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>ë…¸ë˜ì™€ ì˜ ì–´ìš°ëŸ¬ì§€ëŠ” ì˜ìƒ ë•ë¶„ì¸ì§€ ì§§ì§€ë§Œ ê°•í•œ ì¸ìƒì´ ë‚¨ë„¤ìš”..</td>\n",
       "      <td>ì¡°ê¸ˆ ìœ ì¹˜í•˜ì§€ë§Œ ê°€ë³ê²Œ ë³¼ ìˆ˜ëŠ” ìˆëŠ” ì˜í™”ë„¤ìš”!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>boostcamp-sts-v1-train-024</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>êµ°ëŒ€ ê°€ê¸° ì „ì— ë´¤ì—ˆëŠ”ë° ì§„ì§œ ìœˆí„°ìŠ¤ ê°™ì€ ì‚¬ëŒì´ ìƒê´€ì´ë©´ ëª©ìˆ¨ ê±¸ê³  ì‹¸ì›Œë„ í›„íšŒëŠ”...</td>\n",
       "      <td>ì…ëŒ€í•˜ê¸° ì „ì— ë´¤ëŠ”ë° ìœˆí„°ìŠ¤ ê°™ì€ ì‚¬ëŒì´ ì§„ì‹¬ìœ¼ë¡œ ì•„ê»´ì¤€ë‹¤ë©´ ëª©ìˆ¨ì„ ê±¸ê³  ì‹¸ì›Œë„ í›„...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>boostcamp-sts-v1-train-025</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>êµ­ë¯¼ì²­ì›ì— ì˜¬ë¦° ê¸€ ì‚­ì œí•˜ëŠ” ì²­ì™€ëŒ€ ë‰´ë¯¸ë””ì–´ì •ì±…ì‹¤ì€ ì–µìš¸í•œ í”¼í•´ìë¥¼ ì£½ì´ê³  ê²½ì°°ì—ê²Œ...</td>\n",
       "      <td>êµ­ë¯¼ì²­ì› ê¸€ì„ ì‚­ì œí•˜ëŠ” ì²­ì™€ëŒ€ ë‰´ë¯¸ë””ì–´ì •ì±…ì‹¤ì€ ë¶€ë‹¹í•œ í”¼í•´ìë¥¼ ì‚´í•´í•˜ê³ , ê²½ì°°ì— ì¦...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>boostcamp-sts-v1-train-026</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>ì „ë‘í™˜ì„ ì²˜ë²Œí•´ ì£¼ì„¸ìš”</td>\n",
       "      <td>ì´ì¬ìš©ì„ êµ¬ì†í•´ ì£¼ì„¸ìš”</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>boostcamp-sts-v1-train-027</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>ë§ˆì§€ë§‰ìœ¼ë¡œ ë¦¬ëª¨íŠ¸ ê·¼ë¬´ì˜ ì¥ì ì— ëŒ€í•´ ì´ì•¼ê¸°í–ˆëŠ”ë°, ì‹œê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆ...</td>\n",
       "      <td>ë§ˆì§€ë§‰ìœ¼ë¡œ ì¬íƒê·¼ë¬´ì˜ ì¥ì ì— ëŒ€í•´ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ì—ˆê³ , ì‹œê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>boostcamp-sts-v1-train-028</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>ê²¨ìš¸ì‚°ì´ ì˜ˆì˜ì§€ë§Œ ì‚°ì„ ì˜ ëª» íƒ€ì„œ ëŒ€ë¦¬ë§Œì¡± ì¤‘ì…ë‹ˆë‹¤</td>\n",
       "      <td>ê²¨ìš¸ì‚°ì€ ì˜ˆìœë° ì œê°€ ë“±ì‚°ì„ ì˜ ëª»í•´ì„œ ëŒ€ë§Œì¡±ì…ë‹ˆë‹¤.</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>boostcamp-sts-v1-train-029</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>í•œ ì‚¬ëŒì˜ íŒŒë©¸ì„ ì ë‚˜ë¼í•˜ê²Œ ë“œëŸ¬ë‚´ ì¤€ ì˜í™”</td>\n",
       "      <td>í•œ ì‚¬ëŒì˜ íŒŒë©¸ì„ ë“œëŸ¬ë‚´ëŠ” ì˜í™”</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>boostcamp-sts-v1-train-030</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>ê¸ˆìœµìœ„ì›íšŒì˜ ê³µëª¨ì£¼ ê°œì¸ ë°°ì • ì¶•ì†Œ(íì§€)ë¥¼ ë§‰ì•„ì£¼ì„¸ìš”</td>\n",
       "      <td>ê¸ˆìœµê°ë…ì›ì˜ ê³µëª¨ì£¼ ê°œì¸ ë°°ë¶„ ì¶•ì†Œ(íì§€)ë¥¼ ë§‰ì•„ì£¼ì„¸ìš”.</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>boostcamp-sts-v1-train-031</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>ì§€ê¸ˆ ì•„ì£¼ ë§Œì¡±í•´ìš”.</td>\n",
       "      <td>ì§€ê¸ˆì€ ë§¤ìš° ë§Œì¡±í•©ë‹ˆë‹¤.</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>boostcamp-sts-v1-train-032</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>ì €ë„ ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ã…ã…</td>\n",
       "      <td>ì˜¤! ì €ë„ ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ ã…ã…</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>boostcamp-sts-v1-train-033</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>ì˜ ë§Œë“  ì˜í™”êµ°ìš”.</td>\n",
       "      <td>ì˜ ë§Œë“  ì˜í™”ë¼ê³  ìƒê°í•œë‹¤.</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>boostcamp-sts-v1-train-034</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>ì „ì„¤ ë”°ë¼ ì‚¼ì²œë¦¬(ì‚¼ë§Œ ë¦¬ì¸ê°€?)ì— ì˜í•˜ë©´ ì´ ì˜í™”ê°€ ê½¤ ê´œì°®ë‹¤ê³  í•  ë¿ ì•„ë‹ˆë¼ ë‚´...</td>\n",
       "      <td>ì „ì„¤ì— ë”°ë¥´ë©´ ì‚¼ì²œë¦¬(ì‚¼ì²œë¦¬?)ì— ë”°ë¥´ë©´ ì´ ì˜í™”ëŠ” ê½¤ ê´œì°®ì„ ë¿ë§Œ ì•„ë‹ˆë¼ ë‚´ê°€ ì œ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>boostcamp-sts-v1-train-035</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>ë˜ ë¨¹ì–´ ë³´ê³  ì‹¶ë„¤ìš”.</td>\n",
       "      <td>ì–¼ë§ˆë‚˜ ë“œì‹œê³  ì‹¶ì—ˆìœ¼ë©´â€¦</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>boostcamp-sts-v1-train-036</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>ë³´í—˜ì´ ì¬ì‚°ì••ë¥˜ë¥¼ í•´ì„œëŠ” ì•ˆ ë  ì¼ì…ë‹ˆë‹¤.</td>\n",
       "      <td>ë³´í—˜ì€ ì¬ì‚°ì„ ëª°ìˆ˜í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>boostcamp-sts-v1-train-037</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>ì—‘ì†Œ ì—˜ ì „ê´‘íŒ ì‚¬ê±´ ê³µë¡ í™”</td>\n",
       "      <td>ì—‘ì†Œ ì—˜ ë¹Œë³´ë“œ ì‚¬ê±´ ê³µê°œ</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>boostcamp-sts-v1-train-038</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>ì•„ë¬´ë¦¬ ê·¸ë˜ë„ ê±¸ì–´ê°„ë‹¤ëŠ” ì„¤ì •ì€ ì¢€-_-;</td>\n",
       "      <td>í•˜ë‚˜ ì•Œë¦¬ìŠ¨ ë¡œë¨¼ì´ ë²—ì€ ê±´ ì¶©ê²© -_-;;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>boostcamp-sts-v1-train-039</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>íœ´êµë ¹ì„ ë‚´ë ¤ì£¼ì„¸ìš”</td>\n",
       "      <td>ëŒ€êµ¬ê´‘ì—­ì‹œ íœ´êµë ¹ ë‚´ë ¤ì£¼ì‹­ì‹œì˜¤</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>boostcamp-sts-v1-train-040</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>ì´ëŸ° ëª…ì‘ì„ ì™œ ì´ì œ ë´¤ì„ê¹Œ..</td>\n",
       "      <td>ì™œ ì´ëŸ° ëª…ì‘ì„ ì´ì œì•¼ ë³¸ ê±¸ê¹Œ</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>boostcamp-sts-v1-train-041</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>ë‚˜ì´ê°€ ë¬¸ì œì¸ê°€ìš”?</td>\n",
       "      <td>ì €ëŠ” ë¬´ì—‡ì¸ê°€ìš”??</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>boostcamp-sts-v1-train-042</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>ì†Œë…„ë²•ì„ íì§€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤</td>\n",
       "      <td>ì²­ì†Œë…„ ë³´í˜¸ë²• íì§€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>boostcamp-sts-v1-train-043</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>ì˜ë£Œê³„ í™˜ê²½ ê°œì„  ë° ê²½ì°° ì†Œë°©ê³µë¬´ì› ì§€ì›í•´ ì£¼ì„¸ìš”</td>\n",
       "      <td>ì˜ë£Œí™˜ê²½ ê°œì„ ê³¼ ê²½ì°°Â·ì†Œë°©ê´€ ì§€ì› ë¶€íƒë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>boostcamp-sts-v1-train-044</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>ê³µë¬´ì›ì´ ìˆ˜ë‹¹ì„ ë¶€ì •ìˆ˜ë ¹í•˜ì§€ ì•Šë„ë¡ í•´ì£¼ì„¸ìš”</td>\n",
       "      <td>ìµœì €ì„ê¸ˆ ì¸ìƒì— ë”°ë¥¸ ì •ë¶€ ì§€ì›ê¸ˆ ë¶€ì •ìˆ˜ê¸‰ì„ ì ë°œí•˜ì—¬ ì²˜ë²Œí•´ ì£¼ì‹­ì‹œì˜¤</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>boostcamp-sts-v1-train-045</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>ë‚® ì‚°ì±… ë¬´ì¡°ê±´ ì¶”ì²œ~!</td>\n",
       "      <td>ë‚® ì‚°ì±…ì€ ê¼­ ì¶”ì²œí•©ë‹ˆë‹¤!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>boostcamp-sts-v1-train-046</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>ì €ëŠ” ì™œ ì†¥ì— ë“¤ì–´ê°€ê³„ì‹œë‚˜ í–ˆì–´ìš” ã…‹ã…‹</td>\n",
       "      <td>ì €ëŠ” ì‚¬ê³¼ë‚˜ ìš°ìœ ì— í”„ë¡œí‹´ íƒ€ì„œ ë¨¹ì–´ìš” ã…ã…</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>boostcamp-sts-v1-train-047</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>ë™ìƒì´ë‘ ê°™ì´ ë´¤ëŠ”ë° ì‚´ì¸ë° ê·¸ë‹¤ì§€ ë¬´ì„œì›Œí•˜ì§€ ì•Šê³  ì˜ ë³¸ ê²ƒ ê°™ìŒ..</td>\n",
       "      <td>ë‚´ìš©ë„ ê·¸ë ‡ê³  ë³„ë¡œ ë§˜ì— ë“¤ì§€ ì•ŠëŠ”ë‹¤..</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>boostcamp-sts-v1-train-048</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>ì•Œì½”ì˜¬ì¤‘ë…ìê°€ ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì?</td>\n",
       "      <td>ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì ì¥ì• ì¸ì„ ìœ„í•˜ì—¬.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>boostcamp-sts-v1-train-049</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>êµ¬ì˜ì›, ì‹œì˜ì› ì„ ê±°. ì´ì œ ê·¸ë§Œë‘¡ì‹œë‹¤</td>\n",
       "      <td>êµ­íšŒì˜ì›, ë„ì˜ì›, ì‹œì˜ì› ë“¤ 3ì„  ì´ìƒ ì¶œë§ˆ ê¸ˆì§€</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id            source  \\\n",
       "20  boostcamp-sts-v1-train-020     slack-sampled   \n",
       "21  boostcamp-sts-v1-train-021      petition-rtt   \n",
       "22  boostcamp-sts-v1-train-022     slack-sampled   \n",
       "23  boostcamp-sts-v1-train-023      nsmc-sampled   \n",
       "24  boostcamp-sts-v1-train-024          nsmc-rtt   \n",
       "25  boostcamp-sts-v1-train-025      petition-rtt   \n",
       "26  boostcamp-sts-v1-train-026  petition-sampled   \n",
       "27  boostcamp-sts-v1-train-027         slack-rtt   \n",
       "28  boostcamp-sts-v1-train-028         slack-rtt   \n",
       "29  boostcamp-sts-v1-train-029          nsmc-rtt   \n",
       "30  boostcamp-sts-v1-train-030      petition-rtt   \n",
       "31  boostcamp-sts-v1-train-031         slack-rtt   \n",
       "32  boostcamp-sts-v1-train-032     slack-sampled   \n",
       "33  boostcamp-sts-v1-train-033      nsmc-sampled   \n",
       "34  boostcamp-sts-v1-train-034          nsmc-rtt   \n",
       "35  boostcamp-sts-v1-train-035     slack-sampled   \n",
       "36  boostcamp-sts-v1-train-036      petition-rtt   \n",
       "37  boostcamp-sts-v1-train-037      petition-rtt   \n",
       "38  boostcamp-sts-v1-train-038      nsmc-sampled   \n",
       "39  boostcamp-sts-v1-train-039  petition-sampled   \n",
       "40  boostcamp-sts-v1-train-040      nsmc-sampled   \n",
       "41  boostcamp-sts-v1-train-041  petition-sampled   \n",
       "42  boostcamp-sts-v1-train-042  petition-sampled   \n",
       "43  boostcamp-sts-v1-train-043      petition-rtt   \n",
       "44  boostcamp-sts-v1-train-044  petition-sampled   \n",
       "45  boostcamp-sts-v1-train-045         slack-rtt   \n",
       "46  boostcamp-sts-v1-train-046     slack-sampled   \n",
       "47  boostcamp-sts-v1-train-047      nsmc-sampled   \n",
       "48  boostcamp-sts-v1-train-048  petition-sampled   \n",
       "49  boostcamp-sts-v1-train-049  petition-sampled   \n",
       "\n",
       "                                           sentence_1  \\\n",
       "20                                   ì•ë¨¸ë¦¬ ìƒˆë¡œ í•˜ì…¨ìŠµë‹ˆë‹¤. ^^   \n",
       "21                           ê¹€ê¸°ë• ì¡°ì¬í˜„ ì„±í­í–‰ ì² ì €íˆ ìˆ˜ì‚¬í•´ ì£¼ì„¸ìš”!   \n",
       "22                             ë‹µë‹µí•  ë•Œ ë³´ë©´ ì†ì´ ë»¥ ëš«ë¦´ ê²ƒ ê°™ì•„ìš”   \n",
       "23               ë…¸ë˜ì™€ ì˜ ì–´ìš°ëŸ¬ì§€ëŠ” ì˜ìƒ ë•ë¶„ì¸ì§€ ì§§ì§€ë§Œ ê°•í•œ ì¸ìƒì´ ë‚¨ë„¤ìš”..   \n",
       "24  êµ°ëŒ€ ê°€ê¸° ì „ì— ë´¤ì—ˆëŠ”ë° ì§„ì§œ ìœˆí„°ìŠ¤ ê°™ì€ ì‚¬ëŒì´ ìƒê´€ì´ë©´ ëª©ìˆ¨ ê±¸ê³  ì‹¸ì›Œë„ í›„íšŒëŠ”...   \n",
       "25  êµ­ë¯¼ì²­ì›ì— ì˜¬ë¦° ê¸€ ì‚­ì œí•˜ëŠ” ì²­ì™€ëŒ€ ë‰´ë¯¸ë””ì–´ì •ì±…ì‹¤ì€ ì–µìš¸í•œ í”¼í•´ìë¥¼ ì£½ì´ê³  ê²½ì°°ì—ê²Œ...   \n",
       "26                                       ì „ë‘í™˜ì„ ì²˜ë²Œí•´ ì£¼ì„¸ìš”   \n",
       "27  ë§ˆì§€ë§‰ìœ¼ë¡œ ë¦¬ëª¨íŠ¸ ê·¼ë¬´ì˜ ì¥ì ì— ëŒ€í•´ ì´ì•¼ê¸°í–ˆëŠ”ë°, ì‹œê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆ...   \n",
       "28                      ê²¨ìš¸ì‚°ì´ ì˜ˆì˜ì§€ë§Œ ì‚°ì„ ì˜ ëª» íƒ€ì„œ ëŒ€ë¦¬ë§Œì¡± ì¤‘ì…ë‹ˆë‹¤   \n",
       "29                           í•œ ì‚¬ëŒì˜ íŒŒë©¸ì„ ì ë‚˜ë¼í•˜ê²Œ ë“œëŸ¬ë‚´ ì¤€ ì˜í™”   \n",
       "30                     ê¸ˆìœµìœ„ì›íšŒì˜ ê³µëª¨ì£¼ ê°œì¸ ë°°ì • ì¶•ì†Œ(íì§€)ë¥¼ ë§‰ì•„ì£¼ì„¸ìš”   \n",
       "31                                        ì§€ê¸ˆ ì•„ì£¼ ë§Œì¡±í•´ìš”.   \n",
       "32                                    ì €ë„ ë„ˆë¬´ ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ã…ã…   \n",
       "33                                         ì˜ ë§Œë“  ì˜í™”êµ°ìš”.   \n",
       "34  ì „ì„¤ ë”°ë¼ ì‚¼ì²œë¦¬(ì‚¼ë§Œ ë¦¬ì¸ê°€?)ì— ì˜í•˜ë©´ ì´ ì˜í™”ê°€ ê½¤ ê´œì°®ë‹¤ê³  í•  ë¿ ì•„ë‹ˆë¼ ë‚´...   \n",
       "35                                       ë˜ ë¨¹ì–´ ë³´ê³  ì‹¶ë„¤ìš”.   \n",
       "36                            ë³´í—˜ì´ ì¬ì‚°ì••ë¥˜ë¥¼ í•´ì„œëŠ” ì•ˆ ë  ì¼ì…ë‹ˆë‹¤.   \n",
       "37                                    ì—‘ì†Œ ì—˜ ì „ê´‘íŒ ì‚¬ê±´ ê³µë¡ í™”   \n",
       "38                            ì•„ë¬´ë¦¬ ê·¸ë˜ë„ ê±¸ì–´ê°„ë‹¤ëŠ” ì„¤ì •ì€ ì¢€-_-;   \n",
       "39                                         íœ´êµë ¹ì„ ë‚´ë ¤ì£¼ì„¸ìš”   \n",
       "40                                  ì´ëŸ° ëª…ì‘ì„ ì™œ ì´ì œ ë´¤ì„ê¹Œ..   \n",
       "41                                         ë‚˜ì´ê°€ ë¬¸ì œì¸ê°€ìš”?   \n",
       "42                                  ì†Œë…„ë²•ì„ íì§€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤   \n",
       "43                       ì˜ë£Œê³„ í™˜ê²½ ê°œì„  ë° ê²½ì°° ì†Œë°©ê³µë¬´ì› ì§€ì›í•´ ì£¼ì„¸ìš”   \n",
       "44                           ê³µë¬´ì›ì´ ìˆ˜ë‹¹ì„ ë¶€ì •ìˆ˜ë ¹í•˜ì§€ ì•Šë„ë¡ í•´ì£¼ì„¸ìš”   \n",
       "45                                      ë‚® ì‚°ì±… ë¬´ì¡°ê±´ ì¶”ì²œ~!   \n",
       "46                              ì €ëŠ” ì™œ ì†¥ì— ë“¤ì–´ê°€ê³„ì‹œë‚˜ í–ˆì–´ìš” ã…‹ã…‹   \n",
       "47            ë™ìƒì´ë‘ ê°™ì´ ë´¤ëŠ”ë° ì‚´ì¸ë° ê·¸ë‹¤ì§€ ë¬´ì„œì›Œí•˜ì§€ ì•Šê³  ì˜ ë³¸ ê²ƒ ê°™ìŒ..   \n",
       "48                                   ì•Œì½”ì˜¬ì¤‘ë…ìê°€ ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì?   \n",
       "49                              êµ¬ì˜ì›, ì‹œì˜ì› ì„ ê±°. ì´ì œ ê·¸ë§Œë‘¡ì‹œë‹¤   \n",
       "\n",
       "                                           sentence_2  label  binary-label  \n",
       "20                           ê°€ë°©ì— ë„£ì–´ ë‹¤ë‹ˆë©´ì„œ ì¡°ê¸ˆì”© ë¨¹ìŠµë‹ˆë‹¤. ^^    0.0           0.0  \n",
       "21                           ê¹€ê¸°ë•Â·ì¡°ì¬í˜„ ì„±í­í–‰ ì˜í˜¹ ì² ì €íˆ ìˆ˜ì‚¬í•˜ë¼!    4.2           1.0  \n",
       "22                        ì–‘ë³´ë‹¨ í•œì… ë¨¹ëŠ” ìˆœê°„ ê³ ì‚ í’€ë¦´ ê²ƒ ê°™ì•„ìš” ã…‹ã…‹    0.0           0.0  \n",
       "23                         ì¡°ê¸ˆ ìœ ì¹˜í•˜ì§€ë§Œ ê°€ë³ê²Œ ë³¼ ìˆ˜ëŠ” ìˆëŠ” ì˜í™”ë„¤ìš”!    0.0           0.0  \n",
       "24  ì…ëŒ€í•˜ê¸° ì „ì— ë´¤ëŠ”ë° ìœˆí„°ìŠ¤ ê°™ì€ ì‚¬ëŒì´ ì§„ì‹¬ìœ¼ë¡œ ì•„ê»´ì¤€ë‹¤ë©´ ëª©ìˆ¨ì„ ê±¸ê³  ì‹¸ì›Œë„ í›„...    4.2           1.0  \n",
       "25  êµ­ë¯¼ì²­ì› ê¸€ì„ ì‚­ì œí•˜ëŠ” ì²­ì™€ëŒ€ ë‰´ë¯¸ë””ì–´ì •ì±…ì‹¤ì€ ë¶€ë‹¹í•œ í”¼í•´ìë¥¼ ì‚´í•´í•˜ê³ , ê²½ì°°ì— ì¦...    4.0           1.0  \n",
       "26                                       ì´ì¬ìš©ì„ êµ¬ì†í•´ ì£¼ì„¸ìš”    0.2           0.0  \n",
       "27  ë§ˆì§€ë§‰ìœ¼ë¡œ ì¬íƒê·¼ë¬´ì˜ ì¥ì ì— ëŒ€í•´ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ì—ˆê³ , ì‹œê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ...    4.2           1.0  \n",
       "28                      ê²¨ìš¸ì‚°ì€ ì˜ˆìœë° ì œê°€ ë“±ì‚°ì„ ì˜ ëª»í•´ì„œ ëŒ€ë§Œì¡±ì…ë‹ˆë‹¤.    3.2           1.0  \n",
       "29                                  í•œ ì‚¬ëŒì˜ íŒŒë©¸ì„ ë“œëŸ¬ë‚´ëŠ” ì˜í™”    3.6           1.0  \n",
       "30                    ê¸ˆìœµê°ë…ì›ì˜ ê³µëª¨ì£¼ ê°œì¸ ë°°ë¶„ ì¶•ì†Œ(íì§€)ë¥¼ ë§‰ì•„ì£¼ì„¸ìš”.    4.4           1.0  \n",
       "31                                      ì§€ê¸ˆì€ ë§¤ìš° ë§Œì¡±í•©ë‹ˆë‹¤.    4.4           1.0  \n",
       "32                                   ì˜¤! ì €ë„ ì¢‹ì•„í•˜ëŠ” ë…¸ë˜ ã…ã…    4.0           1.0  \n",
       "33                                    ì˜ ë§Œë“  ì˜í™”ë¼ê³  ìƒê°í•œë‹¤.    3.6           1.0  \n",
       "34  ì „ì„¤ì— ë”°ë¥´ë©´ ì‚¼ì²œë¦¬(ì‚¼ì²œë¦¬?)ì— ë”°ë¥´ë©´ ì´ ì˜í™”ëŠ” ê½¤ ê´œì°®ì„ ë¿ë§Œ ì•„ë‹ˆë¼ ë‚´ê°€ ì œ...    4.0           1.0  \n",
       "35                                      ì–¼ë§ˆë‚˜ ë“œì‹œê³  ì‹¶ì—ˆìœ¼ë©´â€¦    1.2           0.0  \n",
       "36                               ë³´í—˜ì€ ì¬ì‚°ì„ ëª°ìˆ˜í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.    3.4           1.0  \n",
       "37                                     ì—‘ì†Œ ì—˜ ë¹Œë³´ë“œ ì‚¬ê±´ ê³µê°œ    0.8           0.0  \n",
       "38                           í•˜ë‚˜ ì•Œë¦¬ìŠ¨ ë¡œë¨¼ì´ ë²—ì€ ê±´ ì¶©ê²© -_-;;    0.0           0.0  \n",
       "39                                   ëŒ€êµ¬ê´‘ì—­ì‹œ íœ´êµë ¹ ë‚´ë ¤ì£¼ì‹­ì‹œì˜¤    2.8           1.0  \n",
       "40                                  ì™œ ì´ëŸ° ëª…ì‘ì„ ì´ì œì•¼ ë³¸ ê±¸ê¹Œ    4.2           1.0  \n",
       "41                                         ì €ëŠ” ë¬´ì—‡ì¸ê°€ìš”??    0.0           0.0  \n",
       "42                              ì²­ì†Œë…„ ë³´í˜¸ë²• íì§€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.    3.8           1.0  \n",
       "43                         ì˜ë£Œí™˜ê²½ ê°œì„ ê³¼ ê²½ì°°Â·ì†Œë°©ê´€ ì§€ì› ë¶€íƒë“œë¦½ë‹ˆë‹¤.    4.4           1.0  \n",
       "44             ìµœì €ì„ê¸ˆ ì¸ìƒì— ë”°ë¥¸ ì •ë¶€ ì§€ì›ê¸ˆ ë¶€ì •ìˆ˜ê¸‰ì„ ì ë°œí•˜ì—¬ ì²˜ë²Œí•´ ì£¼ì‹­ì‹œì˜¤    0.8           0.0  \n",
       "45                                     ë‚® ì‚°ì±…ì€ ê¼­ ì¶”ì²œí•©ë‹ˆë‹¤!    4.0           1.0  \n",
       "46                           ì €ëŠ” ì‚¬ê³¼ë‚˜ ìš°ìœ ì— í”„ë¡œí‹´ íƒ€ì„œ ë¨¹ì–´ìš” ã…ã…    0.0           0.0  \n",
       "47                             ë‚´ìš©ë„ ê·¸ë ‡ê³  ë³„ë¡œ ë§˜ì— ë“¤ì§€ ì•ŠëŠ”ë‹¤..    0.0           0.0  \n",
       "48                                  ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ì ì¥ì• ì¸ì„ ìœ„í•˜ì—¬.    1.0           0.0  \n",
       "49                       êµ­íšŒì˜ì›, ë„ì˜ì›, ì‹œì˜ì› ë“¤ 3ì„  ì´ìƒ ì¶œë§ˆ ê¸ˆì§€    0.8           0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_temp: train row 10ê°œë§Œ ë½‘ì•„ì„œ í…ŒìŠ¤íŠ¸\n",
    "train_temp = train[20:50]\n",
    "train_temp = preprocess(train_temp)\n",
    "train_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passportKey found: 2caa5e5496fed85692709081d304c63cf6eaa3bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "check_spell:   0%|          | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/indexes/range.py:414\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_spell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_temp\n",
      "Cell \u001b[0;32mIn[8], line 80\u001b[0m, in \u001b[0;36mcheck_spell\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m     77\u001b[0m passport_key \u001b[38;5;241m=\u001b[39m get_passport_key()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_1\u001b[39m\u001b[38;5;124m'\u001b[39m])), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_spell\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 80\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39munescape(check(\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, passport_key))\n\u001b[1;32m     81\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39munescape(check(dataframe\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_2\u001b[39m\u001b[38;5;124m'\u001b[39m], passport_key))        \n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/indexing.py:1146\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/frame.py:4012\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4006\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4009\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4010\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4011\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 4012\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[1;32m   4015\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   4016\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/indexes/range.py:416\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "train_temp = check_spell(train_temp)\n",
    "train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original     : ì—¬ìš´ì´ ë‚¨ëŠ”ë‹¤ë¼ëŠ” í‘œí˜„ì„ ì´ëŸ´ë•Œ ì“°ëŠ”ê²ƒì´ì£ !\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'repeat_normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# s2 = 'ìˆ˜ë§ì€ë°˜ë¡€ì„ì´ê²¨ëƒ‡ë”°'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal     : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m s2_r \u001b[38;5;241m=\u001b[39m \u001b[43mprep_repeats\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter repeats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms2_r\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m s2_rs \u001b[38;5;241m=\u001b[39m prep_spacing(s2_r)\n",
      "Cell \u001b[0;32mIn[1], line 96\u001b[0m, in \u001b[0;36mprep_repeats\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     93\u001b[0m     normalized_text \u001b[38;5;241m=\u001b[39m repeat_normalize(text, num_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalized_text\n\u001b[0;32m---> 96\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ, ì (.) ë“±ì˜ ë¬¸ì¥ ë¶€í˜¸ ë°˜ë³µì„ ìµœëŒ€ 2ê°œë¡œ ì¤„ì„\u001b[39;00m\n\u001b[1;32m     99\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([!?.])\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,}\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "Cell \u001b[0;32mIn[1], line 93\u001b[0m, in \u001b[0;36mprep_repeats.<locals>.normalize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_text\u001b[39m(text):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# ë°˜ë³µë˜ëŠ” ê¸€ì(ê°íƒ„ì‚¬, ì›ƒìŒì†Œë¦¬ ë“±)ë¥¼ ìµœëŒ€ 2ê°œë¡œ ì¤„ì„\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     normalized_text \u001b[38;5;241m=\u001b[39m \u001b[43mrepeat_normalize\u001b[49m(text, num_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalized_text\n",
      "\u001b[0;31mNameError\u001b[0m: name 'repeat_normalize' is not defined"
     ]
    }
   ],
   "source": [
    "n = 120\n",
    "n = n-2\n",
    "s2 = test['sentence_1'][n]\n",
    "\n",
    "# s2 = 'ìˆ˜ë§ì€ë°˜ë¡€ì„ì´ê²¨ëƒ‡ë”°'\n",
    "\n",
    "print(f'original     : {s2}')\n",
    "s2_r = prep_repeats(s2)\n",
    "print(f'after repeats: {s2_r}')\n",
    "s2_rs = prep_spacing(s2_r)\n",
    "print(f'after spacing: {s2_rs}')\n",
    "s2_rsn = prep_naver(s2_rs)\n",
    "print(f'after naver  : {s2_rsn}')\n",
    "\n",
    "print()\n",
    "\n",
    "s3 = s2\n",
    "print(f'original     : {s3}')\n",
    "s3_r = prep_repeats(s3)\n",
    "print(f'after repeats: {s3_r}')\n",
    "s3_rn = prep_naver(s3_r)\n",
    "print(f'after naver  : {s3_rn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ì˜¤!! ì•„ì•„ ìº¬ìº¬!! ë„ˆë¬´ ì›ƒê²¨ã…‹ã…‹!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ì˜ˆì‹œ ë¬¸ì¥\n",
    "text = \"ì˜¤ì˜¤ì˜¤ì˜¤!! ì•„ì•„ì•„ì•„ ìº¬ìº¬ìº¬ìº¬!! ë„ˆë¬´ ì›ƒê²¨ã…‹ã…‹ã…‹ã…‹!!\"\n",
    "normalized_text = normalize_text(text)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"klue/roberta-base\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Failed to fetch the page, status code: 403",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ì˜ˆì‹œë¡œ test ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•´ ì ìš©\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m test_tokenized \u001b[38;5;241m=\u001b[39m tokenizing(tokenizer, \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[132], line 119\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    117\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(prep_repeats)\n\u001b[1;32m    118\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(prep_repeats)\n\u001b[0;32m--> 119\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep_naver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(prep_naver)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/series.py:4753\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/heejun-base/lib/python3.9/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[132], line 82\u001b[0m, in \u001b[0;36mprep_naver\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m passport_key \u001b[38;5;241m=\u001b[39m \u001b[43mget_passport_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m text \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39munescape(check(text, passport_key))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "Cell \u001b[0;32mIn[132], line 37\u001b[0m, in \u001b[0;36mprep_naver.<locals>.get_passport_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassportKey not found in the HTML response.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to fetch the page, status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mConnectionError\u001b[0m: Failed to fetch the page, status code: 403"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def tokenizing(tokenizer, dataframe):\n",
    "    # ìƒˆ ì—´ì„ ì¶”ê°€í•  ì¤€ë¹„\n",
    "    dataframe['s1_tokens'] = None\n",
    "    dataframe['s2_tokens'] = None\n",
    "    \n",
    "    for idx, item in tqdm(dataframe.iterrows(), desc='tokenizing', total=len(dataframe)):\n",
    "        # sentence_1 í† í¬ë‚˜ì´ì§•\n",
    "        s1_outputs = tokenizer(\n",
    "            item['sentence_1'],\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        # sentence_2 í† í¬ë‚˜ì´ì§•\n",
    "        s2_outputs = tokenizer(\n",
    "            item['sentence_2'],\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "        # í† í¬ë‚˜ì´ì§•ëœ ê²°ê³¼ë¥¼ ê°ê° ìƒˆ ì—´ì— ì €ì¥\n",
    "        dataframe.at[idx, 's1_tokens'] = tokenizer.convert_ids_to_tokens(s1_outputs['input_ids'])\n",
    "        dataframe.at[idx, 's2_tokens'] = tokenizer.convert_ids_to_tokens(s2_outputs['input_ids'])\n",
    "    \n",
    "    return dataframe\n",
    "        \n",
    "# ì˜ˆì‹œë¡œ test ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•´ ì ìš©\n",
    "test_tokenized = tokenizing(tokenizer, preprocess(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 rows with [UNK] tokens\n"
     ]
    }
   ],
   "source": [
    "# find [UNK] tokens in s1_tokens and s2_tokens\n",
    "# make a new df 'test_unk' that contains rows with [UNK] tokens\n",
    "def find_unk(df):\n",
    "    count = 0\n",
    "    unk_indices = []\n",
    "    for idx, item in df.iterrows():\n",
    "        if '[UNK]' in item['s1_tokens'] or '[UNK]' in item['s2_tokens']:\n",
    "            unk_indices.append(idx)\n",
    "            count += 1\n",
    "    print(f'Found {count} rows with [UNK] tokens')\n",
    "    return df.loc[unk_indices]\n",
    "\n",
    "test_unk = find_unk(test_tokenized)\n",
    "# test_unk.to_csv('a_unk.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 2nd row of test_unk\n",
    "\n",
    "with open('slang.txt', 'w') as f:\n",
    "    for n in range(len(test_unk)):\n",
    "        if '[UNK]' in test_unk.iloc[n]['s1_tokens']:\n",
    "            f.write(f'{test_unk.iloc[n][\"sentence_1\"]}\\n')\n",
    "            f.write(f'{test_unk.iloc[n][\"s1_tokens\"]}\\n')\n",
    "        if '[UNK]' in test_unk.iloc[n]['s2_tokens']:\n",
    "            f.write(f'{test_unk.iloc[n][\"sentence_2\"]}\\n')\n",
    "            f.write(f'{test_unk.iloc[n][\"s2_tokens\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang = {\n",
    "    'ì—¬ì­™ë„ë¡': 'ë¬¼ì–´ë³´ë„ë¡',\n",
    "    'ë¿…ê°„ë‹¤': 'ë©‹ìˆë‹¤',\n",
    "    'ìˆë‚˜ìš¯ã…ã…': 'ìˆë‚˜ìš”ã…ã…',\n",
    "    'ê¶êµ¼í•©ë‹ˆë‹¤': 'ê¶ê¸ˆí•©ë‹ˆë‹¤',\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[PAD]', '[SEP]']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id to token example\n",
    "id = [0, 1, 2]\n",
    "token = tokenizer.convert_ids_to_tokens(id)\n",
    "token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'ê°€ìƒ',\n",
       " '##í™”',\n",
       " '##í',\n",
       " '##ê±°ë˜ì†Œ',\n",
       " 'íì‡„',\n",
       " '##í•˜',\n",
       " '##ì§€',\n",
       " 'ë§',\n",
       " '##ê³ ',\n",
       " '[SEP]',\n",
       " 'ê°€ìƒ',\n",
       " '##í™”',\n",
       " '##í',\n",
       " 'ê±°ë˜ì†Œ',\n",
       " 'íì‡„',\n",
       " 'ë°˜ëŒ€',\n",
       " '##í•©ë‹ˆë‹¤',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id to token\n",
    "tokens = tokenizer.convert_ids_to_tokens(test_tokenized[0][0])\n",
    "tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
